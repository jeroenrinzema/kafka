services:
  kafka:
    image: apache/kafka:3.9.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafka-data:/var/lib/kafka/data
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5

  # Log generator - produces sample log data to Kafka
  log-generator:
    image: edenhill/kcat:1.7.1
    hostname: log-generator
    container_name: log-generator
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: /bin/sh
    command:
      - -c
      - |
        # Wait for Kafka to be fully ready
        sleep 10

        # Generate logs continuously
        counter=0
        while true; do
          counter=$$((counter + 1))
          case $$((counter % 7)) in
            0) LEVEL="ERROR" ;;
            1) LEVEL="WARN" ;;
            2) LEVEL="DEBUG" ;;
            *) LEVEL="INFO" ;;
          esac
          case $$((counter % 5)) in
            0) APP="auth-service" ;;
            1) APP="api-gateway" ;;
            2) APP="user-service" ;;
            3) APP="payment-service" ;;
            4) APP="order-service" ;;
          esac
          case $$((counter % 8)) in
            0) MSG="Request processed" ;;
            1) MSG="Connection established" ;;
            2) MSG="Cache miss" ;;
            3) MSG="Query executed" ;;
            4) MSG="Session created" ;;
            5) MSG="Token validated" ;;
            6) MSG="Health check passed" ;;
            7) MSG="Config loaded" ;;
          esac
          TRACE_ID=$$(cat /dev/urandom | tr -dc 'a-f0-9' | head -c 32)
          USER_ID=$$((counter % 10000))
          LATENCY=$$((counter % 500))
          TIMESTAMP=$$(date -u +%Y-%m-%dT%H:%M:%S.000Z)

          echo "{\"@timestamp\":\"$$TIMESTAMP\",\"level\":\"$$LEVEL\",\"app_name\":\"$$APP\",\"message\":\"$$MSG\",\"trace_id\":\"$$TRACE_ID\",\"user_id\":$$USER_ID,\"latency_ms\":$$LATENCY}" | \
            kcat -P -b kafka:9092 -t application-logs

          sleep 1
        done

  # Kafka Connect with Elasticsearch connector
  connect:
    image: confluentinc/cp-kafka-connect:7.5.3
    hostname: connect
    container_name: connect
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: connect-cluster
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components
    command:
      - bash
      - -c
      - |
        echo "Installing Elasticsearch connector..."
        confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:latest
        echo "Starting Kafka Connect..."
        /etc/confluent/docker/run
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8083/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 60s

  # Elasticsearch single-node cluster
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.3
    hostname: elasticsearch
    container_name: elasticsearch
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    healthcheck:
      test:
        ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  # Kibana for visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.3
    hostname: kibana
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - xpack.security.enabled=false
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  # Kafka UI for monitoring
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://connect:8083

volumes:
  kafka-data:
  elasticsearch-data:
